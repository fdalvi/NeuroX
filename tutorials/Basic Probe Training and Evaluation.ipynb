{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aebc884",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c82f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurox.data.extraction.transformers_extractor as transformers_extractor\n",
    "import neurox.data.loader as data_loader\n",
    "import neurox.interpretation.utils as utils\n",
    "import neurox.interpretation.linear_probe as linear_probe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe254ad",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2faee3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths to your word and label files \n",
    "train_sentences = \"data/pos_train.word\"\n",
    "train_labels = \"data/pos_train.label\"\n",
    "dev_sentences = \"data/pos_dev.word\"\n",
    "dev_labels = \"data/pos_dev.label\" \n",
    "test_sentences = \"data/pos_test.word\"\n",
    "test_labels = \"data/pos_test.label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c05680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\r\n",
      "Mr. Vinken is chairman of Elsevier N.V. , the Dutch publishing group .\r\n",
      "Rudolph Agnew , 55 years old and former chairman of Consolidated Gold Fields PLC , was named a nonexecutive director of this British industrial conglomerate .\r\n",
      "A form of asbestos once used to make Kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than 30 years ago , researchers reported .\r\n",
      "The asbestos fiber , crocidolite , is unusually resilient once it enters the lungs , with even brief exposures to it causing symptoms that show up decades later , researchers said .\r\n",
      "Lorillard Inc. , the unit of New York-based Loews Corp. that makes Kent cigarettes , stopped using crocidolite in its Micronite cigarette filters in 1956 .\r\n",
      "Although preliminary findings were reported more than a year ago , the latest results appear in today 's New England Journal of Medicine , a forum likely to bring new attention to the problem .\r\n",
      "A Lorillard spokewoman said , `` This is an old story .\r\n",
      "We 're talking about years ago before anyone heard of asbestos having any questionable properties .\r\n",
      "There is no asbestos in our products now . ''\r\n"
     ]
    }
   ],
   "source": [
    "# inspect data\n",
    "!cat \"data/pos_train.word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac26e05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP NNP , CD NNS JJ , MD VB DT NN IN DT JJ NN NNP CD .\r\n",
      "NNP NNP VBZ NN IN NNP NNP , DT NNP VBG NN .\r\n",
      "NNP NNP , CD NNS JJ CC JJ NN IN NNP NNP NNP NNP , VBD VBN DT JJ NN IN DT JJ JJ NN .\r\n",
      "DT NN IN NN RB VBN TO VB NNP NN NNS VBZ VBN DT JJ NN IN NN NNS IN DT NN IN NNS VBN TO PRP RBR IN CD NNS IN , NNS VBD .\r\n",
      "DT NN NN , NN , VBZ RB JJ IN PRP VBZ DT NNS , IN RB JJ NNS TO PRP VBG NNS WDT VBP RP NNS JJ , NNS VBD .\r\n",
      "NNP NNP , DT NN IN JJ JJ NNP NNP WDT VBZ NNP NNS , VBD VBG NN IN PRP$ NN NN NNS IN CD .\r\n",
      "IN JJ NNS VBD VBN RBR IN DT NN IN , DT JJS NNS VBP IN NN POS NNP NNP NNP IN NNP , DT NN JJ TO VB JJ NN TO DT NN .\r\n",
      "DT NNP NN VBD , `` DT VBZ DT JJ NN .\r\n",
      "PRP VBP VBG IN NNS IN IN NN VBD IN NN VBG DT JJ NNS .\r\n",
      "EX VBZ DT NN IN PRP$ NNS RB . ''\r\n"
     ]
    }
   ],
   "source": [
    "!cat \"data/pos_train.label\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926d06c",
   "metadata": {},
   "source": [
    "# Extract Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f92698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input corpus\n",
      "Preparing output file\n",
      "Extracting representations from model\n",
      "Sentence         : \"Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\"\n",
      "Original    (018): ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
      "Tokenized   (025): ['[CLS]', 'pierre', 'vin', '##ken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'none', '##x', '##ec', '##utive', 'director', 'nov', '.', '29', '.', '[SEP]']\n",
      "Filtered   (023): ['pierre', 'vin', '##ken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'none', '##x', '##ec', '##utive', 'director', 'nov', '.', '29', '.']\n",
      "Detokenized (018): ['pierre', 'vin##ken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'none##x##ec##utive', 'director', 'nov.', '29', '.']\n",
      "Counter: 23\n",
      "===================================================================\n",
      "Hidden states:  (13, 18, 768)\n",
      "# Extracted words:  18\n",
      "Sentence         : \"Mr. Vinken is chairman of Elsevier N.V. , the Dutch publishing group .\"\n",
      "Original    (013): ['Mr.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N.V.', ',', 'the', 'Dutch', 'publishing', 'group', '.']\n",
      "Tokenized   (021): ['[CLS]', 'mr', '.', 'vin', '##ken', 'is', 'chairman', 'of', 'else', '##vier', 'n', '.', 'v', '.', ',', 'the', 'dutch', 'publishing', 'group', '.', '[SEP]']\n",
      "Filtered   (019): ['mr', '.', 'vin', '##ken', 'is', 'chairman', 'of', 'else', '##vier', 'n', '.', 'v', '.', ',', 'the', 'dutch', 'publishing', 'group', '.']\n",
      "Detokenized (013): ['mr.', 'vin##ken', 'is', 'chairman', 'of', 'else##vier', 'n.v.', ',', 'the', 'dutch', 'publishing', 'group', '.']\n",
      "Counter: 19\n",
      "===================================================================\n",
      "Hidden states:  (13, 13, 768)\n",
      "# Extracted words:  13\n",
      "Sentence         : \"Rudolph Agnew , 55 years old and former chairman of Consolidated Gold Fields PLC , was named a nonexecutive director of this British industrial conglomerate .\"\n",
      "Original    (026): ['Rudolph', 'Agnew', ',', '55', 'years', 'old', 'and', 'former', 'chairman', 'of', 'Consolidated', 'Gold', 'Fields', 'PLC', ',', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'British', 'industrial', 'conglomerate', '.']\n",
      "Tokenized   (033): ['[CLS]', 'rudolph', 'ag', '##ne', '##w', ',', '55', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', ',', 'was', 'named', 'a', 'none', '##x', '##ec', '##utive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '.', '[SEP]']\n",
      "Filtered   (031): ['rudolph', 'ag', '##ne', '##w', ',', '55', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', ',', 'was', 'named', 'a', 'none', '##x', '##ec', '##utive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '.']\n",
      "Detokenized (026): ['rudolph', 'ag##ne##w', ',', '55', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', ',', 'was', 'named', 'a', 'none##x##ec##utive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '.']\n",
      "Counter: 31\n",
      "===================================================================\n",
      "Hidden states:  (13, 26, 768)\n",
      "# Extracted words:  26\n",
      "Sentence         : \"A form of asbestos once used to make Kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than 30 years ago , researchers reported .\"\n",
      "Original    (036): ['A', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'Kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of', 'workers', 'exposed', 'to', 'it', 'more', 'than', '30', 'years', 'ago', ',', 'researchers', 'reported', '.']\n",
      "Tokenized   (038): ['[CLS]', 'a', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of', 'workers', 'exposed', 'to', 'it', 'more', 'than', '30', 'years', 'ago', ',', 'researchers', 'reported', '.', '[SEP]']\n",
      "Filtered   (036): ['a', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of', 'workers', 'exposed', 'to', 'it', 'more', 'than', '30', 'years', 'ago', ',', 'researchers', 'reported', '.']\n",
      "Detokenized (036): ['a', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of', 'workers', 'exposed', 'to', 'it', 'more', 'than', '30', 'years', 'ago', ',', 'researchers', 'reported', '.']\n",
      "Counter: 36\n",
      "===================================================================\n",
      "Hidden states:  (13, 36, 768)\n",
      "# Extracted words:  36\n",
      "Sentence         : \"The asbestos fiber , crocidolite , is unusually resilient once it enters the lungs , with even brief exposures to it causing symptoms that show up decades later , researchers said .\"\n",
      "Original    (032): ['The', 'asbestos', 'fiber', ',', 'crocidolite', ',', 'is', 'unusually', 'resilient', 'once', 'it', 'enters', 'the', 'lungs', ',', 'with', 'even', 'brief', 'exposures', 'to', 'it', 'causing', 'symptoms', 'that', 'show', 'up', 'decades', 'later', ',', 'researchers', 'said', '.']\n",
      "Tokenized   (040): ['[CLS]', 'the', 'asbestos', 'fiber', ',', 'cr', '##oc', '##ido', '##lite', ',', 'is', 'unusually', 'res', '##ili', '##ent', 'once', 'it', 'enters', 'the', 'lungs', ',', 'with', 'even', 'brief', 'exposure', '##s', 'to', 'it', 'causing', 'symptoms', 'that', 'show', 'up', 'decades', 'later', ',', 'researchers', 'said', '.', '[SEP]']\n",
      "Filtered   (038): ['the', 'asbestos', 'fiber', ',', 'cr', '##oc', '##ido', '##lite', ',', 'is', 'unusually', 'res', '##ili', '##ent', 'once', 'it', 'enters', 'the', 'lungs', ',', 'with', 'even', 'brief', 'exposure', '##s', 'to', 'it', 'causing', 'symptoms', 'that', 'show', 'up', 'decades', 'later', ',', 'researchers', 'said', '.']\n",
      "Detokenized (032): ['the', 'asbestos', 'fiber', ',', 'cr##oc##ido##lite', ',', 'is', 'unusually', 'res##ili##ent', 'once', 'it', 'enters', 'the', 'lungs', ',', 'with', 'even', 'brief', 'exposure##s', 'to', 'it', 'causing', 'symptoms', 'that', 'show', 'up', 'decades', 'later', ',', 'researchers', 'said', '.']\n",
      "Counter: 38\n",
      "===================================================================\n",
      "Hidden states:  (13, 32, 768)\n",
      "# Extracted words:  32\n",
      "Sentence         : \"Lorillard Inc. , the unit of New York-based Loews Corp. that makes Kent cigarettes , stopped using crocidolite in its Micronite cigarette filters in 1956 .\"\n",
      "Original    (026): ['Lorillard', 'Inc.', ',', 'the', 'unit', 'of', 'New', 'York-based', 'Loews', 'Corp.', 'that', 'makes', 'Kent', 'cigarettes', ',', 'stopped', 'using', 'crocidolite', 'in', 'its', 'Micronite', 'cigarette', 'filters', 'in', '1956', '.']\n",
      "Tokenized   (041): ['[CLS]', 'lori', '##llar', '##d', 'inc', '.', ',', 'the', 'unit', 'of', 'new', 'york', '-', 'based', 'lo', '##ew', '##s', 'corp', '.', 'that', 'makes', 'kent', 'cigarettes', ',', 'stopped', 'using', 'cr', '##oc', '##ido', '##lite', 'in', 'its', 'micro', '##ni', '##te', 'cigarette', 'filters', 'in', '1956', '.', '[SEP]']\n",
      "Filtered   (039): ['lori', '##llar', '##d', 'inc', '.', ',', 'the', 'unit', 'of', 'new', 'york', '-', 'based', 'lo', '##ew', '##s', 'corp', '.', 'that', 'makes', 'kent', 'cigarettes', ',', 'stopped', 'using', 'cr', '##oc', '##ido', '##lite', 'in', 'its', 'micro', '##ni', '##te', 'cigarette', 'filters', 'in', '1956', '.']\n",
      "Detokenized (026): ['lori##llar##d', 'inc.', ',', 'the', 'unit', 'of', 'new', 'york-based', 'lo##ew##s', 'corp.', 'that', 'makes', 'kent', 'cigarettes', ',', 'stopped', 'using', 'cr##oc##ido##lite', 'in', 'its', 'micro##ni##te', 'cigarette', 'filters', 'in', '1956', '.']\n",
      "Counter: 39\n",
      "===================================================================\n",
      "Hidden states:  (13, 26, 768)\n",
      "# Extracted words:  26\n",
      "Sentence         : \"Although preliminary findings were reported more than a year ago , the latest results appear in today 's New England Journal of Medicine , a forum likely to bring new attention to the problem .\"\n",
      "Original    (035): ['Although', 'preliminary', 'findings', 'were', 'reported', 'more', 'than', 'a', 'year', 'ago', ',', 'the', 'latest', 'results', 'appear', 'in', 'today', \"'s\", 'New', 'England', 'Journal', 'of', 'Medicine', ',', 'a', 'forum', 'likely', 'to', 'bring', 'new', 'attention', 'to', 'the', 'problem', '.']\n",
      "Tokenized   (038): ['[CLS]', 'although', 'preliminary', 'findings', 'were', 'reported', 'more', 'than', 'a', 'year', 'ago', ',', 'the', 'latest', 'results', 'appear', 'in', 'today', \"'\", 's', 'new', 'england', 'journal', 'of', 'medicine', ',', 'a', 'forum', 'likely', 'to', 'bring', 'new', 'attention', 'to', 'the', 'problem', '.', '[SEP]']\n",
      "Filtered   (036): ['although', 'preliminary', 'findings', 'were', 'reported', 'more', 'than', 'a', 'year', 'ago', ',', 'the', 'latest', 'results', 'appear', 'in', 'today', \"'\", 's', 'new', 'england', 'journal', 'of', 'medicine', ',', 'a', 'forum', 'likely', 'to', 'bring', 'new', 'attention', 'to', 'the', 'problem', '.']\n",
      "Detokenized (035): ['although', 'preliminary', 'findings', 'were', 'reported', 'more', 'than', 'a', 'year', 'ago', ',', 'the', 'latest', 'results', 'appear', 'in', 'today', \"'s\", 'new', 'england', 'journal', 'of', 'medicine', ',', 'a', 'forum', 'likely', 'to', 'bring', 'new', 'attention', 'to', 'the', 'problem', '.']\n",
      "Counter: 36\n",
      "===================================================================\n",
      "Hidden states:  (13, 35, 768)\n",
      "# Extracted words:  35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence         : \"A Lorillard spokewoman said , `` This is an old story .\"\n",
      "Original    (012): ['A', 'Lorillard', 'spokewoman', 'said', ',', '``', 'This', 'is', 'an', 'old', 'story', '.']\n",
      "Tokenized   (018): ['[CLS]', 'a', 'lori', '##llar', '##d', 'spoke', '##woman', 'said', ',', '`', '`', 'this', 'is', 'an', 'old', 'story', '.', '[SEP]']\n",
      "Filtered   (016): ['a', 'lori', '##llar', '##d', 'spoke', '##woman', 'said', ',', '`', '`', 'this', 'is', 'an', 'old', 'story', '.']\n",
      "Detokenized (012): ['a', 'lori##llar##d', 'spoke##woman', 'said', ',', '``', 'this', 'is', 'an', 'old', 'story', '.']\n",
      "Counter: 16\n",
      "===================================================================\n",
      "Hidden states:  (13, 12, 768)\n",
      "# Extracted words:  12\n",
      "Sentence         : \"We 're talking about years ago before anyone heard of asbestos having any questionable properties .\"\n",
      "Original    (016): ['We', \"'re\", 'talking', 'about', 'years', 'ago', 'before', 'anyone', 'heard', 'of', 'asbestos', 'having', 'any', 'questionable', 'properties', '.']\n",
      "Tokenized   (019): ['[CLS]', 'we', \"'\", 're', 'talking', 'about', 'years', 'ago', 'before', 'anyone', 'heard', 'of', 'asbestos', 'having', 'any', 'questionable', 'properties', '.', '[SEP]']\n",
      "Filtered   (017): ['we', \"'\", 're', 'talking', 'about', 'years', 'ago', 'before', 'anyone', 'heard', 'of', 'asbestos', 'having', 'any', 'questionable', 'properties', '.']\n",
      "Detokenized (016): ['we', \"'re\", 'talking', 'about', 'years', 'ago', 'before', 'anyone', 'heard', 'of', 'asbestos', 'having', 'any', 'questionable', 'properties', '.']\n",
      "Counter: 17\n",
      "===================================================================\n",
      "Hidden states:  (13, 16, 768)\n",
      "# Extracted words:  16\n",
      "Sentence         : \"There is no asbestos in our products now . ''\"\n",
      "Original    (010): ['There', 'is', 'no', 'asbestos', 'in', 'our', 'products', 'now', '.', \"''\"]\n",
      "Tokenized   (013): ['[CLS]', 'there', 'is', 'no', 'asbestos', 'in', 'our', 'products', 'now', '.', \"'\", \"'\", '[SEP]']\n",
      "Filtered   (011): ['there', 'is', 'no', 'asbestos', 'in', 'our', 'products', 'now', '.', \"'\", \"'\"]\n",
      "Detokenized (010): ['there', 'is', 'no', 'asbestos', 'in', 'our', 'products', 'now', '.', \"''\"]\n",
      "Counter: 11\n",
      "===================================================================\n",
      "Hidden states:  (13, 10, 768)\n",
      "# Extracted words:  10\n"
     ]
    }
   ],
   "source": [
    "# extract activations for the train sentences \n",
    "transformers_extractor.extract_representations('bert-base-uncased',\n",
    "    train_sentences,\n",
    "    'train_activations.json',\n",
    "    aggregation=\"average\" #last, first\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b1cb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input corpus\n",
      "Preparing output file\n",
      "Extracting representations from model\n",
      "Sentence         : \"The Arizona Corporations Commission authorized an 11.5 % rate increase at Tucson Electric Power Co. , substantially lower than recommended last month by a commission hearing officer and barely half the rise sought by the utility .\"\n",
      "Original    (037): ['The', 'Arizona', 'Corporations', 'Commission', 'authorized', 'an', '11.5', '%', 'rate', 'increase', 'at', 'Tucson', 'Electric', 'Power', 'Co.', ',', 'substantially', 'lower', 'than', 'recommended', 'last', 'month', 'by', 'a', 'commission', 'hearing', 'officer', 'and', 'barely', 'half', 'the', 'rise', 'sought', 'by', 'the', 'utility', '.']\n",
      "Tokenized   (042): ['[CLS]', 'the', 'arizona', 'corporations', 'commission', 'authorized', 'an', '11', '.', '5', '%', 'rate', 'increase', 'at', 'tucson', 'electric', 'power', 'co', '.', ',', 'substantially', 'lower', 'than', 'recommended', 'last', 'month', 'by', 'a', 'commission', 'hearing', 'officer', 'and', 'barely', 'half', 'the', 'rise', 'sought', 'by', 'the', 'utility', '.', '[SEP]']\n",
      "Filtered   (040): ['the', 'arizona', 'corporations', 'commission', 'authorized', 'an', '11', '.', '5', '%', 'rate', 'increase', 'at', 'tucson', 'electric', 'power', 'co', '.', ',', 'substantially', 'lower', 'than', 'recommended', 'last', 'month', 'by', 'a', 'commission', 'hearing', 'officer', 'and', 'barely', 'half', 'the', 'rise', 'sought', 'by', 'the', 'utility', '.']\n",
      "Detokenized (037): ['the', 'arizona', 'corporations', 'commission', 'authorized', 'an', '11.5', '%', 'rate', 'increase', 'at', 'tucson', 'electric', 'power', 'co.', ',', 'substantially', 'lower', 'than', 'recommended', 'last', 'month', 'by', 'a', 'commission', 'hearing', 'officer', 'and', 'barely', 'half', 'the', 'rise', 'sought', 'by', 'the', 'utility', '.']\n",
      "Counter: 40\n",
      "===================================================================\n",
      "Hidden states:  (13, 37, 768)\n",
      "# Extracted words:  37\n",
      "Sentence         : \"The ruling follows a host of problems at Tucson Electric , including major write-downs , a 60 % slash in the common stock dividend and the departure of former Chairman Einar Greve during a company investigation of his stock sales .\"\n",
      "Original    (041): ['The', 'ruling', 'follows', 'a', 'host', 'of', 'problems', 'at', 'Tucson', 'Electric', ',', 'including', 'major', 'write-downs', ',', 'a', '60', '%', 'slash', 'in', 'the', 'common', 'stock', 'dividend', 'and', 'the', 'departure', 'of', 'former', 'Chairman', 'Einar', 'Greve', 'during', 'a', 'company', 'investigation', 'of', 'his', 'stock', 'sales', '.']\n",
      "Tokenized   (048): ['[CLS]', 'the', 'ruling', 'follows', 'a', 'host', 'of', 'problems', 'at', 'tucson', 'electric', ',', 'including', 'major', 'write', '-', 'downs', ',', 'a', '60', '%', 'slash', 'in', 'the', 'common', 'stock', 'divide', '##nd', 'and', 'the', 'departure', 'of', 'former', 'chairman', 'ein', '##ar', 'gr', '##eve', 'during', 'a', 'company', 'investigation', 'of', 'his', 'stock', 'sales', '.', '[SEP]']\n",
      "Filtered   (046): ['the', 'ruling', 'follows', 'a', 'host', 'of', 'problems', 'at', 'tucson', 'electric', ',', 'including', 'major', 'write', '-', 'downs', ',', 'a', '60', '%', 'slash', 'in', 'the', 'common', 'stock', 'divide', '##nd', 'and', 'the', 'departure', 'of', 'former', 'chairman', 'ein', '##ar', 'gr', '##eve', 'during', 'a', 'company', 'investigation', 'of', 'his', 'stock', 'sales', '.']\n",
      "Detokenized (041): ['the', 'ruling', 'follows', 'a', 'host', 'of', 'problems', 'at', 'tucson', 'electric', ',', 'including', 'major', 'write-downs', ',', 'a', '60', '%', 'slash', 'in', 'the', 'common', 'stock', 'divide##nd', 'and', 'the', 'departure', 'of', 'former', 'chairman', 'ein##ar', 'gr##eve', 'during', 'a', 'company', 'investigation', 'of', 'his', 'stock', 'sales', '.']\n",
      "Counter: 46\n",
      "===================================================================\n",
      "Hidden states:  (13, 41, 768)\n",
      "# Extracted words:  41\n",
      "Sentence         : \"The Arizona regulatory ruling calls for $ 42 million in added revenue yearly , compared with a $ 57 million boost proposed by the commission hearing officer .\"\n",
      "Original    (028): ['The', 'Arizona', 'regulatory', 'ruling', 'calls', 'for', '$', '42', 'million', 'in', 'added', 'revenue', 'yearly', ',', 'compared', 'with', 'a', '$', '57', 'million', 'boost', 'proposed', 'by', 'the', 'commission', 'hearing', 'officer', '.']\n",
      "Tokenized   (030): ['[CLS]', 'the', 'arizona', 'regulatory', 'ruling', 'calls', 'for', '$', '42', 'million', 'in', 'added', 'revenue', 'yearly', ',', 'compared', 'with', 'a', '$', '57', 'million', 'boost', 'proposed', 'by', 'the', 'commission', 'hearing', 'officer', '.', '[SEP]']\n",
      "Filtered   (028): ['the', 'arizona', 'regulatory', 'ruling', 'calls', 'for', '$', '42', 'million', 'in', 'added', 'revenue', 'yearly', ',', 'compared', 'with', 'a', '$', '57', 'million', 'boost', 'proposed', 'by', 'the', 'commission', 'hearing', 'officer', '.']\n",
      "Detokenized (028): ['the', 'arizona', 'regulatory', 'ruling', 'calls', 'for', '$', '42', 'million', 'in', 'added', 'revenue', 'yearly', ',', 'compared', 'with', 'a', '$', '57', 'million', 'boost', 'proposed', 'by', 'the', 'commission', 'hearing', 'officer', '.']\n",
      "Counter: 28\n",
      "===================================================================\n",
      "Hidden states:  (13, 28, 768)\n",
      "# Extracted words:  28\n",
      "Sentence         : \"The company had sought increases totaling $ 80.3 million , or 22 % .\"\n",
      "Original    (014): ['The', 'company', 'had', 'sought', 'increases', 'totaling', '$', '80.3', 'million', ',', 'or', '22', '%', '.']\n",
      "Tokenized   (018): ['[CLS]', 'the', 'company', 'had', 'sought', 'increases', 'totaling', '$', '80', '.', '3', 'million', ',', 'or', '22', '%', '.', '[SEP]']\n",
      "Filtered   (016): ['the', 'company', 'had', 'sought', 'increases', 'totaling', '$', '80', '.', '3', 'million', ',', 'or', '22', '%', '.']\n",
      "Detokenized (014): ['the', 'company', 'had', 'sought', 'increases', 'totaling', '$', '80.3', 'million', ',', 'or', '22', '%', '.']\n",
      "Counter: 16\n",
      "===================================================================\n",
      "Hidden states:  (13, 14, 768)\n",
      "# Extracted words:  14\n",
      "Sentence         : \"The decision was announced after trading ended .\"\n",
      "Original    (008): ['The', 'decision', 'was', 'announced', 'after', 'trading', 'ended', '.']\n",
      "Tokenized   (010): ['[CLS]', 'the', 'decision', 'was', 'announced', 'after', 'trading', 'ended', '.', '[SEP]']\n",
      "Filtered   (008): ['the', 'decision', 'was', 'announced', 'after', 'trading', 'ended', '.']\n",
      "Detokenized (008): ['the', 'decision', 'was', 'announced', 'after', 'trading', 'ended', '.']\n",
      "Counter: 8\n",
      "===================================================================\n",
      "Hidden states:  (13, 8, 768)\n",
      "# Extracted words:  8\n",
      "Sentence         : \"Tucson Electric closed at $ 20.875 a share , down 25 cents , in New York Stock Exchange composite trading .\"\n",
      "Original    (021): ['Tucson', 'Electric', 'closed', 'at', '$', '20.875', 'a', 'share', ',', 'down', '25', 'cents', ',', 'in', 'New', 'York', 'Stock', 'Exchange', 'composite', 'trading', '.']\n",
      "Tokenized   (025): ['[CLS]', 'tucson', 'electric', 'closed', 'at', '$', '20', '.', '875', 'a', 'share', ',', 'down', '25', 'cents', ',', 'in', 'new', 'york', 'stock', 'exchange', 'composite', 'trading', '.', '[SEP]']\n",
      "Filtered   (023): ['tucson', 'electric', 'closed', 'at', '$', '20', '.', '875', 'a', 'share', ',', 'down', '25', 'cents', ',', 'in', 'new', 'york', 'stock', 'exchange', 'composite', 'trading', '.']\n",
      "Detokenized (021): ['tucson', 'electric', 'closed', 'at', '$', '20.875', 'a', 'share', ',', 'down', '25', 'cents', ',', 'in', 'new', 'york', 'stock', 'exchange', 'composite', 'trading', '.']\n",
      "Counter: 23\n",
      "===================================================================\n",
      "Hidden states:  (13, 21, 768)\n",
      "# Extracted words:  21\n",
      "Sentence         : \"A Tucson Electric spokesman said the utility was disappointed by the commission 's decision and `` concerned about the financial integrity of the company .\"\n",
      "Original    (025): ['A', 'Tucson', 'Electric', 'spokesman', 'said', 'the', 'utility', 'was', 'disappointed', 'by', 'the', 'commission', \"'s\", 'decision', 'and', '``', 'concerned', 'about', 'the', 'financial', 'integrity', 'of', 'the', 'company', '.']\n",
      "Tokenized   (029): ['[CLS]', 'a', 'tucson', 'electric', 'spokesman', 'said', 'the', 'utility', 'was', 'disappointed', 'by', 'the', 'commission', \"'\", 's', 'decision', 'and', '`', '`', 'concerned', 'about', 'the', 'financial', 'integrity', 'of', 'the', 'company', '.', '[SEP]']\n",
      "Filtered   (027): ['a', 'tucson', 'electric', 'spokesman', 'said', 'the', 'utility', 'was', 'disappointed', 'by', 'the', 'commission', \"'\", 's', 'decision', 'and', '`', '`', 'concerned', 'about', 'the', 'financial', 'integrity', 'of', 'the', 'company', '.']\n",
      "Detokenized (025): ['a', 'tucson', 'electric', 'spokesman', 'said', 'the', 'utility', 'was', 'disappointed', 'by', 'the', 'commission', \"'s\", 'decision', 'and', '``', 'concerned', 'about', 'the', 'financial', 'integrity', 'of', 'the', 'company', '.']\n",
      "Counter: 27\n",
      "===================================================================\n",
      "Hidden states:  (13, 25, 768)\n",
      "# Extracted words:  25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence         : \"South Korean President Roh Tae Woo , brushing aside suggestions that the won be revalued again , said the currency 's current level against the dollar is `` appropriate . ''\"\n",
      "Original    (031): ['South', 'Korean', 'President', 'Roh', 'Tae', 'Woo', ',', 'brushing', 'aside', 'suggestions', 'that', 'the', 'won', 'be', 'revalued', 'again', ',', 'said', 'the', 'currency', \"'s\", 'current', 'level', 'against', 'the', 'dollar', 'is', '``', 'appropriate', '.', \"''\"]\n",
      "Tokenized   (040): ['[CLS]', 'south', 'korean', 'president', 'ro', '##h', 'tae', 'woo', ',', 'brushing', 'aside', 'suggestions', 'that', 'the', 'won', 'be', 'rev', '##al', '##ue', '##d', 'again', ',', 'said', 'the', 'currency', \"'\", 's', 'current', 'level', 'against', 'the', 'dollar', 'is', '`', '`', 'appropriate', '.', \"'\", \"'\", '[SEP]']\n",
      "Filtered   (038): ['south', 'korean', 'president', 'ro', '##h', 'tae', 'woo', ',', 'brushing', 'aside', 'suggestions', 'that', 'the', 'won', 'be', 'rev', '##al', '##ue', '##d', 'again', ',', 'said', 'the', 'currency', \"'\", 's', 'current', 'level', 'against', 'the', 'dollar', 'is', '`', '`', 'appropriate', '.', \"'\", \"'\"]\n",
      "Detokenized (031): ['south', 'korean', 'president', 'ro##h', 'tae', 'woo', ',', 'brushing', 'aside', 'suggestions', 'that', 'the', 'won', 'be', 'rev##al##ue##d', 'again', ',', 'said', 'the', 'currency', \"'s\", 'current', 'level', 'against', 'the', 'dollar', 'is', '``', 'appropriate', '.', \"''\"]\n",
      "Counter: 38\n",
      "===================================================================\n",
      "Hidden states:  (13, 31, 768)\n",
      "# Extracted words:  31\n",
      "Sentence         : \"His comments , made in response to reporters ' questions at the National Press Club here , signaled that Seoul is resisting U.S. pressure for a further rise in the currency 's value .\"\n",
      "Original    (034): ['His', 'comments', ',', 'made', 'in', 'response', 'to', 'reporters', \"'\", 'questions', 'at', 'the', 'National', 'Press', 'Club', 'here', ',', 'signaled', 'that', 'Seoul', 'is', 'resisting', 'U.S.', 'pressure', 'for', 'a', 'further', 'rise', 'in', 'the', 'currency', \"'s\", 'value', '.']\n",
      "Tokenized   (040): ['[CLS]', 'his', 'comments', ',', 'made', 'in', 'response', 'to', 'reporters', \"'\", 'questions', 'at', 'the', 'national', 'press', 'club', 'here', ',', 'signaled', 'that', 'seoul', 'is', 'resisting', 'u', '.', 's', '.', 'pressure', 'for', 'a', 'further', 'rise', 'in', 'the', 'currency', \"'\", 's', 'value', '.', '[SEP]']\n",
      "Filtered   (038): ['his', 'comments', ',', 'made', 'in', 'response', 'to', 'reporters', \"'\", 'questions', 'at', 'the', 'national', 'press', 'club', 'here', ',', 'signaled', 'that', 'seoul', 'is', 'resisting', 'u', '.', 's', '.', 'pressure', 'for', 'a', 'further', 'rise', 'in', 'the', 'currency', \"'\", 's', 'value', '.']\n",
      "Detokenized (034): ['his', 'comments', ',', 'made', 'in', 'response', 'to', 'reporters', \"'\", 'questions', 'at', 'the', 'national', 'press', 'club', 'here', ',', 'signaled', 'that', 'seoul', 'is', 'resisting', 'u.s.', 'pressure', 'for', 'a', 'further', 'rise', 'in', 'the', 'currency', \"'s\", 'value', '.']\n",
      "Counter: 38\n",
      "===================================================================\n",
      "Hidden states:  (13, 34, 768)\n",
      "# Extracted words:  34\n",
      "Sentence         : \"The U.S. wants a higher won to make South Korea 's exports more expensive and help trim Seoul 's trade surplus .\"\n",
      "Original    (022): ['The', 'U.S.', 'wants', 'a', 'higher', 'won', 'to', 'make', 'South', 'Korea', \"'s\", 'exports', 'more', 'expensive', 'and', 'help', 'trim', 'Seoul', \"'s\", 'trade', 'surplus', '.']\n",
      "Tokenized   (029): ['[CLS]', 'the', 'u', '.', 's', '.', 'wants', 'a', 'higher', 'won', 'to', 'make', 'south', 'korea', \"'\", 's', 'exports', 'more', 'expensive', 'and', 'help', 'trim', 'seoul', \"'\", 's', 'trade', 'surplus', '.', '[SEP]']\n",
      "Filtered   (027): ['the', 'u', '.', 's', '.', 'wants', 'a', 'higher', 'won', 'to', 'make', 'south', 'korea', \"'\", 's', 'exports', 'more', 'expensive', 'and', 'help', 'trim', 'seoul', \"'\", 's', 'trade', 'surplus', '.']\n",
      "Detokenized (022): ['the', 'u.s.', 'wants', 'a', 'higher', 'won', 'to', 'make', 'south', 'korea', \"'s\", 'exports', 'more', 'expensive', 'and', 'help', 'trim', 'seoul', \"'s\", 'trade', 'surplus', '.']\n",
      "Counter: 27\n",
      "===================================================================\n",
      "Hidden states:  (13, 22, 768)\n",
      "# Extracted words:  22\n"
     ]
    }
   ],
   "source": [
    "# extract activations for the dev sentences \n",
    "transformers_extractor.extract_representations('bert-base-uncased',\n",
    "    dev_sentences,\n",
    "    'dev_activations.json',\n",
    "    aggregation=\"average\" #last, first\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68db479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input corpus\n",
      "Preparing output file\n",
      "Extracting representations from model\n",
      "Sentence         : \"Rockwell International Corp. 's Tulsa unit said it signed a tentative agreement extending its contract with Boeing Co. to provide structural parts for Boeing 's 747 jetliners .\"\n",
      "Original    (028): ['Rockwell', 'International', 'Corp.', \"'s\", 'Tulsa', 'unit', 'said', 'it', 'signed', 'a', 'tentative', 'agreement', 'extending', 'its', 'contract', 'with', 'Boeing', 'Co.', 'to', 'provide', 'structural', 'parts', 'for', 'Boeing', \"'s\", '747', 'jetliners', '.']\n",
      "Tokenized   (036): ['[CLS]', 'rockwell', 'international', 'corp', '.', \"'\", 's', 'tulsa', 'unit', 'said', 'it', 'signed', 'a', 'tentative', 'agreement', 'extending', 'its', 'contract', 'with', 'boeing', 'co', '.', 'to', 'provide', 'structural', 'parts', 'for', 'boeing', \"'\", 's', '747', 'jet', '##liner', '##s', '.', '[SEP]']\n",
      "Filtered   (034): ['rockwell', 'international', 'corp', '.', \"'\", 's', 'tulsa', 'unit', 'said', 'it', 'signed', 'a', 'tentative', 'agreement', 'extending', 'its', 'contract', 'with', 'boeing', 'co', '.', 'to', 'provide', 'structural', 'parts', 'for', 'boeing', \"'\", 's', '747', 'jet', '##liner', '##s', '.']\n",
      "Detokenized (028): ['rockwell', 'international', 'corp.', \"'s\", 'tulsa', 'unit', 'said', 'it', 'signed', 'a', 'tentative', 'agreement', 'extending', 'its', 'contract', 'with', 'boeing', 'co.', 'to', 'provide', 'structural', 'parts', 'for', 'boeing', \"'s\", '747', 'jet##liner##s', '.']\n",
      "Counter: 34\n",
      "===================================================================\n",
      "Hidden states:  (13, 28, 768)\n",
      "# Extracted words:  28\n",
      "Sentence         : \"Rockwell said the agreement calls for it to supply 200 additional so-called shipsets for the planes .\"\n",
      "Original    (017): ['Rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Tokenized   (022): ['[CLS]', 'rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so', '-', 'called', 'ships', '##ets', 'for', 'the', 'planes', '.', '[SEP]']\n",
      "Filtered   (020): ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so', '-', 'called', 'ships', '##ets', 'for', 'the', 'planes', '.']\n",
      "Detokenized (017): ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'ships##ets', 'for', 'the', 'planes', '.']\n",
      "Counter: 20\n",
      "===================================================================\n",
      "Hidden states:  (13, 17, 768)\n",
      "# Extracted words:  17\n",
      "Sentence         : \"These include , among other parts , each jetliner 's two major bulkheads , a pressure floor , torque box , fixed leading edges for the wings and an aft keel beam .\"\n",
      "Original    (033): ['These', 'include', ',', 'among', 'other', 'parts', ',', 'each', 'jetliner', \"'s\", 'two', 'major', 'bulkheads', ',', 'a', 'pressure', 'floor', ',', 'torque', 'box', ',', 'fixed', 'leading', 'edges', 'for', 'the', 'wings', 'and', 'an', 'aft', 'keel', 'beam', '.']\n",
      "Tokenized   (038): ['[CLS]', 'these', 'include', ',', 'among', 'other', 'parts', ',', 'each', 'jet', '##liner', \"'\", 's', 'two', 'major', 'bulk', '##heads', ',', 'a', 'pressure', 'floor', ',', 'torque', 'box', ',', 'fixed', 'leading', 'edges', 'for', 'the', 'wings', 'and', 'an', 'aft', 'keel', 'beam', '.', '[SEP]']\n",
      "Filtered   (036): ['these', 'include', ',', 'among', 'other', 'parts', ',', 'each', 'jet', '##liner', \"'\", 's', 'two', 'major', 'bulk', '##heads', ',', 'a', 'pressure', 'floor', ',', 'torque', 'box', ',', 'fixed', 'leading', 'edges', 'for', 'the', 'wings', 'and', 'an', 'aft', 'keel', 'beam', '.']\n",
      "Detokenized (033): ['these', 'include', ',', 'among', 'other', 'parts', ',', 'each', 'jet##liner', \"'s\", 'two', 'major', 'bulk##heads', ',', 'a', 'pressure', 'floor', ',', 'torque', 'box', ',', 'fixed', 'leading', 'edges', 'for', 'the', 'wings', 'and', 'an', 'aft', 'keel', 'beam', '.']\n",
      "Counter: 36\n",
      "===================================================================\n",
      "Hidden states:  (13, 33, 768)\n",
      "# Extracted words:  33\n",
      "Sentence         : \"Under the existing contract , Rockwell said , it has already delivered 793 of the shipsets to Boeing .\"\n",
      "Original    (019): ['Under', 'the', 'existing', 'contract', ',', 'Rockwell', 'said', ',', 'it', 'has', 'already', 'delivered', '793', 'of', 'the', 'shipsets', 'to', 'Boeing', '.']\n",
      "Tokenized   (023): ['[CLS]', 'under', 'the', 'existing', 'contract', ',', 'rockwell', 'said', ',', 'it', 'has', 'already', 'delivered', '79', '##3', 'of', 'the', 'ships', '##ets', 'to', 'boeing', '.', '[SEP]']\n",
      "Filtered   (021): ['under', 'the', 'existing', 'contract', ',', 'rockwell', 'said', ',', 'it', 'has', 'already', 'delivered', '79', '##3', 'of', 'the', 'ships', '##ets', 'to', 'boeing', '.']\n",
      "Detokenized (019): ['under', 'the', 'existing', 'contract', ',', 'rockwell', 'said', ',', 'it', 'has', 'already', 'delivered', '79##3', 'of', 'the', 'ships##ets', 'to', 'boeing', '.']\n",
      "Counter: 21\n",
      "===================================================================\n",
      "Hidden states:  (13, 19, 768)\n",
      "# Extracted words:  19\n",
      "Sentence         : \"Rockwell , based in El Segundo , Calif. , is an aerospace , electronics , automotive and graphics concern .\"\n",
      "Original    (020): ['Rockwell', ',', 'based', 'in', 'El', 'Segundo', ',', 'Calif.', ',', 'is', 'an', 'aerospace', ',', 'electronics', ',', 'automotive', 'and', 'graphics', 'concern', '.']\n",
      "Tokenized   (026): ['[CLS]', 'rockwell', ',', 'based', 'in', 'el', 'se', '##gun', '##do', ',', 'cal', '##if', '.', ',', 'is', 'an', 'aerospace', ',', 'electronics', ',', 'automotive', 'and', 'graphics', 'concern', '.', '[SEP]']\n",
      "Filtered   (024): ['rockwell', ',', 'based', 'in', 'el', 'se', '##gun', '##do', ',', 'cal', '##if', '.', ',', 'is', 'an', 'aerospace', ',', 'electronics', ',', 'automotive', 'and', 'graphics', 'concern', '.']\n",
      "Detokenized (020): ['rockwell', ',', 'based', 'in', 'el', 'se##gun##do', ',', 'cal##if.', ',', 'is', 'an', 'aerospace', ',', 'electronics', ',', 'automotive', 'and', 'graphics', 'concern', '.']\n",
      "Counter: 24\n",
      "===================================================================\n",
      "Hidden states:  (13, 20, 768)\n",
      "# Extracted words:  20\n",
      "Sentence         : \"Frank Carlucci III was named to this telecommunications company 's board , filling the vacancy created by the death of William Sobey last May .\"\n",
      "Original    (025): ['Frank', 'Carlucci', 'III', 'was', 'named', 'to', 'this', 'telecommunications', 'company', \"'s\", 'board', ',', 'filling', 'the', 'vacancy', 'created', 'by', 'the', 'death', 'of', 'William', 'Sobey', 'last', 'May', '.']\n",
      "Tokenized   (030): ['[CLS]', 'frank', 'carl', '##ucci', 'iii', 'was', 'named', 'to', 'this', 'telecommunications', 'company', \"'\", 's', 'board', ',', 'filling', 'the', 'vacancy', 'created', 'by', 'the', 'death', 'of', 'william', 'sob', '##ey', 'last', 'may', '.', '[SEP]']\n",
      "Filtered   (028): ['frank', 'carl', '##ucci', 'iii', 'was', 'named', 'to', 'this', 'telecommunications', 'company', \"'\", 's', 'board', ',', 'filling', 'the', 'vacancy', 'created', 'by', 'the', 'death', 'of', 'william', 'sob', '##ey', 'last', 'may', '.']\n",
      "Detokenized (025): ['frank', 'carl##ucci', 'iii', 'was', 'named', 'to', 'this', 'telecommunications', 'company', \"'s\", 'board', ',', 'filling', 'the', 'vacancy', 'created', 'by', 'the', 'death', 'of', 'william', 'sob##ey', 'last', 'may', '.']\n",
      "Counter: 28\n",
      "===================================================================\n",
      "Hidden states:  (13, 25, 768)\n",
      "# Extracted words:  25\n",
      "Sentence         : \"Mr. Carlucci , 59 years old , served as defense secretary in the Reagan administration .\"\n",
      "Original    (016): ['Mr.', 'Carlucci', ',', '59', 'years', 'old', ',', 'served', 'as', 'defense', 'secretary', 'in', 'the', 'Reagan', 'administration', '.']\n",
      "Tokenized   (020): ['[CLS]', 'mr', '.', 'carl', '##ucci', ',', '59', 'years', 'old', ',', 'served', 'as', 'defense', 'secretary', 'in', 'the', 'reagan', 'administration', '.', '[SEP]']\n",
      "Filtered   (018): ['mr', '.', 'carl', '##ucci', ',', '59', 'years', 'old', ',', 'served', 'as', 'defense', 'secretary', 'in', 'the', 'reagan', 'administration', '.']\n",
      "Detokenized (016): ['mr.', 'carl##ucci', ',', '59', 'years', 'old', ',', 'served', 'as', 'defense', 'secretary', 'in', 'the', 'reagan', 'administration', '.']\n",
      "Counter: 18\n",
      "===================================================================\n",
      "Hidden states:  (13, 16, 768)\n",
      "# Extracted words:  16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence         : \"In January , he accepted the position of vice chairman of Carlyle Group , a merchant banking concern .\"\n",
      "Original    (019): ['In', 'January', ',', 'he', 'accepted', 'the', 'position', 'of', 'vice', 'chairman', 'of', 'Carlyle', 'Group', ',', 'a', 'merchant', 'banking', 'concern', '.']\n",
      "Tokenized   (022): ['[CLS]', 'in', 'january', ',', 'he', 'accepted', 'the', 'position', 'of', 'vice', 'chairman', 'of', 'carly', '##le', 'group', ',', 'a', 'merchant', 'banking', 'concern', '.', '[SEP]']\n",
      "Filtered   (020): ['in', 'january', ',', 'he', 'accepted', 'the', 'position', 'of', 'vice', 'chairman', 'of', 'carly', '##le', 'group', ',', 'a', 'merchant', 'banking', 'concern', '.']\n",
      "Detokenized (019): ['in', 'january', ',', 'he', 'accepted', 'the', 'position', 'of', 'vice', 'chairman', 'of', 'carly##le', 'group', ',', 'a', 'merchant', 'banking', 'concern', '.']\n",
      "Counter: 20\n",
      "===================================================================\n",
      "Hidden states:  (13, 19, 768)\n",
      "# Extracted words:  19\n",
      "Sentence         : \"SHEARSON LEHMAN HUTTON Inc .\"\n",
      "Original    (005): ['SHEARSON', 'LEHMAN', 'HUTTON', 'Inc', '.']\n",
      "Tokenized   (008): ['[CLS]', 'shear', '##son', 'lehman', 'hutton', 'inc', '.', '[SEP]']\n",
      "Filtered   (006): ['shear', '##son', 'lehman', 'hutton', 'inc', '.']\n",
      "Detokenized (005): ['shear##son', 'lehman', 'hutton', 'inc', '.']\n",
      "Counter: 6\n",
      "===================================================================\n",
      "Hidden states:  (13, 5, 768)\n",
      "# Extracted words:  5\n",
      "Sentence         : \"Thomas E. Meador , 42 years old , was named president and chief operating officer of Balcor Co. , a Skokie , Ill. , subsidiary of this New York investment banking firm .\"\n",
      "Original    (033): ['Thomas', 'E.', 'Meador', ',', '42', 'years', 'old', ',', 'was', 'named', 'president', 'and', 'chief', 'operating', 'officer', 'of', 'Balcor', 'Co.', ',', 'a', 'Skokie', ',', 'Ill.', ',', 'subsidiary', 'of', 'this', 'New', 'York', 'investment', 'banking', 'firm', '.']\n",
      "Tokenized   (042): ['[CLS]', 'thomas', 'e', '.', 'mead', '##or', ',', '42', 'years', 'old', ',', 'was', 'named', 'president', 'and', 'chief', 'operating', 'officer', 'of', 'bal', '##cor', 'co', '.', ',', 'a', 'sk', '##oki', '##e', ',', 'ill', '.', ',', 'subsidiary', 'of', 'this', 'new', 'york', 'investment', 'banking', 'firm', '.', '[SEP]']\n",
      "Filtered   (040): ['thomas', 'e', '.', 'mead', '##or', ',', '42', 'years', 'old', ',', 'was', 'named', 'president', 'and', 'chief', 'operating', 'officer', 'of', 'bal', '##cor', 'co', '.', ',', 'a', 'sk', '##oki', '##e', ',', 'ill', '.', ',', 'subsidiary', 'of', 'this', 'new', 'york', 'investment', 'banking', 'firm', '.']\n",
      "Detokenized (033): ['thomas', 'e.', 'mead##or', ',', '42', 'years', 'old', ',', 'was', 'named', 'president', 'and', 'chief', 'operating', 'officer', 'of', 'bal##cor', 'co.', ',', 'a', 'sk##oki##e', ',', 'ill.', ',', 'subsidiary', 'of', 'this', 'new', 'york', 'investment', 'banking', 'firm', '.']\n",
      "Counter: 40\n",
      "===================================================================\n",
      "Hidden states:  (13, 33, 768)\n",
      "# Extracted words:  33\n"
     ]
    }
   ],
   "source": [
    "# extract activations for the test sentences \n",
    "transformers_extractor.extract_representations('bert-base-uncased',\n",
    "    test_sentences,\n",
    "    'test_activations.json',\n",
    "    aggregation=\"average\" #last, first\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ef91a",
   "metadata": {},
   "source": [
    "# Train Linear Probe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae96309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json activations from train_activations.json...\n",
      "10 13.0\n"
     ]
    }
   ],
   "source": [
    "# add code for training a probe here\n",
    "activations, num_layers = data_loader.load_activations('train_activations.json', 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00d7fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = data_loader.load_data(train_sentences, train_labels, activations, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c47f507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  224\n",
      "length of source dictionary:  142\n",
      "length of target dictionary:  29\n",
      "224\n",
      "Total instances: 224\n",
      "['cancer', 'year', 'decades', 'British', 'Micronite', 'years', 'fiber', 'bring', 'attention', '29', 'nonexecutive', 'products', 'about', 'it', '55', 'caused', 'ago', 'There', 'even', 'Kent']\n",
      "Number of samples:  224\n",
      "Stats: Labels with their frequencies in the final set\n",
      "JJS 1\n",
      "VBN 5\n",
      "NNS 19\n",
      "CD 5\n",
      "RB 4\n",
      "CC 1\n",
      "VBP 3\n",
      "`` 1\n",
      "TO 5\n",
      ". 10\n",
      "MD 1\n",
      "VBZ 7\n",
      "JJ 18\n",
      "'' 1\n",
      "WDT 2\n",
      "POS 1\n",
      "NNP 25\n",
      "IN 25\n",
      ", 15\n",
      "RBR 2\n",
      "RP 1\n",
      "VB 3\n",
      "VBD 7\n",
      "PRP 4\n",
      "NN 30\n",
      "PRP$ 2\n",
      "VBG 5\n",
      "DT 20\n",
      "EX 1\n"
     ]
    }
   ],
   "source": [
    "X, y, mapping = utils.create_tensors(tokens, activations, 'NN')\n",
    "label2idx, idx2label, src2idx, idx2src = mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d843df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification probe\n",
      "Creating model...\n",
      "Number of training instances: 224\n",
      "Number of classes: 29\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007191181182861328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch [1/10]",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba06fdfd72d408db10891833132a1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [1/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Loss: 0.1105\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004636287689208984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch [2/10]",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fb0de6543a4759b7edfb25723d1cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [2/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/10], Loss: 0.0470\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00424647331237793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch [3/10]",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caa32ef0b2f460780a5669886a1d0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [3/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/10], Loss: 0.0447\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004083156585693359,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch [4/10]",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422c823b649e470ba9c5e9be876d27a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [4/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4/10], Loss: 0.0408\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004159212112426758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch [5/10]",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1157d28ef342aca601bac1ef6be78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [5/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/10], Loss: 0.0353\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004272937774658203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch [6/10]",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982a60059c344f87b5056dec04befd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [6/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6/10], Loss: 0.0297\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004262685775756836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch [7/10]",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22e4ca57a514237a477bee164fce139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [7/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7/10], Loss: 0.0248\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004319429397583008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch [8/10]",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b7a93ef17a4054af988010fc5f2731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [8/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8/10], Loss: 0.0209\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004349470138549805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch [9/10]",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2a73043ddc41e5a76214783ccc36c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [9/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9/10], Loss: 0.0180\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004022836685180664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "epoch [10/10]",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8361f68eb15f419c9d7195a238c97ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [10/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10], Loss: 0.0159\n"
     ]
    }
   ],
   "source": [
    "probe = linear_probe.train_logistic_regression_probe(X, y, lambda_l1=0.001, lambda_l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378bbc45",
   "metadata": {},
   "source": [
    "# Evaluate Linear Probe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a616f",
   "metadata": {},
   "source": [
    "## Evaluate On Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "814e3d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json activations from dev_activations.json...\n",
      "10 13.0\n",
      "Number of tokens:  261\n",
      "length of source dictionary:  158\n",
      "length of target dictionary:  26\n",
      "261\n",
      "Total instances: 261\n",
      "['Tae', 'including', 'decision', 'expensive', '25', 'follows', 'Korean', 'hearing', 'about', 'Einar', 'aside', \"''\", 'value', 'half', 'trade', 'after', 'U.S.', 'lower', 'a', 'be']\n",
      "Number of samples:  261\n",
      "Stats: Labels with their frequencies in the final set\n",
      "$ 4\n",
      "VBN 9\n",
      "NNS 10\n",
      "CD 11\n",
      "RB 6\n",
      "JJR 3\n",
      "CC 5\n",
      "`` 2\n",
      "TO 2\n",
      ". 10\n",
      "VBZ 5\n",
      "JJ 14\n",
      "'' 1\n",
      "PDT 1\n",
      "POS 6\n",
      "NNP 34\n",
      "IN 27\n",
      ", 11\n",
      "RBR 1\n",
      "RP 1\n",
      "VBD 9\n",
      "VB 4\n",
      "NN 49\n",
      "PRP$ 2\n",
      "VBG 4\n",
      "DT 30\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004069089889526367,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaa6983b9a64efab692740298e61d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (accuracy) of the probe: 0.15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'__OVERALL__': 0.14942528735632185}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations, num_layers = data_loader.load_activations('dev_activations.json', 768)\n",
    "tokens = data_loader.load_data(dev_sentences, dev_labels, activations, 512)\n",
    "X_dev, y_dev, mapping = utils.create_tensors(tokens, activations, 'NN')\n",
    "scores = linear_probe.evaluate_probe(probe, X_dev, y_dev)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5e222",
   "metadata": {},
   "source": [
    "## Evaluate On Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e74198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json activations from test_activations.json...\n",
      "10 13.0\n",
      "Number of tokens:  215\n",
      "length of source dictionary:  134\n",
      "length of target dictionary:  21\n",
      "215\n",
      "Total instances: 215\n",
      "['Segundo', 'death', 'E.', 'signed', 'fixed', 'years', 'provide', 'agreement', 'it', '200', 'each', 'secretary', 'jetliners', 'already', 'Meador', 'Carlucci', 'vacancy', 'Thomas', 'a', 'planes']\n",
      "Number of samples:  215\n",
      "Stats: Labels with their frequencies in the final set\n",
      "VBN 6\n",
      "NNS 14\n",
      "CD 6\n",
      "RB 1\n",
      "CC 3\n",
      "VBP 1\n",
      "TO 4\n",
      ". 10\n",
      "VBZ 3\n",
      "JJ 11\n",
      "POS 4\n",
      "NNP 39\n",
      "IN 18\n",
      ", 22\n",
      "VB 2\n",
      "VBD 8\n",
      "PRP 4\n",
      "NN 34\n",
      "PRP$ 1\n",
      "VBG 5\n",
      "DT 19\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00395965576171875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24577df11420440386f55e0f7d2b7655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (accuracy) of the probe: 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'__OVERALL__': 0.004651162790697674}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations, num_layers = data_loader.load_activations('test_activations.json', 768)\n",
    "tokens = data_loader.load_data(test_sentences, test_labels, activations, 512)\n",
    "X_test, y_test, mapping = utils.create_tensors(tokens, activations, 'NN')\n",
    "scores = linear_probe.evaluate_probe(probe, X_test, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34681f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
