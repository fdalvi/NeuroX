{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e1eb03",
   "metadata": {},
   "source": [
    "# Binary Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261b9d3",
   "metadata": {},
   "source": [
    "In this notebook we will use the neurox library to create a binary labeled dataset based on a pattern. we will be using the annotate data function from the neurox.data.annotate module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cff3a2",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d2a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurox.data.annotate import annotate_data\n",
    "import neurox.data.extraction.transformers_extractor as transformers_extractor\n",
    "import neurox.data.loader as data_loader\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad2203",
   "metadata": {},
   "source": [
    "# Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1aed1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the year 1969, Neil Armstrong became the first person to set foot on the moon during the Apollo 11 mission.\r\n",
      "The Berlin Wall, which divided East and West Germany, stood from 1961 until its fall in 1989.\r\n",
      "In 1776, the United States declared its independence from Great Britain with the signing of the Declaration of Independence.\r\n",
      "The year 1945 marked the end of World War II, with the surrender of Germany and Japan.\r\n",
      "The internet as we know it today began to take shape in 1969, when the first host-to-host connection was established between two computers.\r\n",
      "The devastating earthquake and tsunami in Japan occurred in 2011, causing widespread destruction and a nuclear disaster at the Fukushima Daiichi power plant.\r\n",
      "The Chernobyl nuclear disaster took place in 1986, when a reactor at the Chernobyl power plant in Ukraine exploded, releasing a significant amount of radioactive material.\r\n",
      "The year 1492 is famous for Christopher Columbus's first voyage to the Americas, which opened up a new era of exploration and colonization.\r\n",
      "The Women's Suffrage Movement achieved a significant victory in 1920 with the ratification of the 19th Amendment, granting women the right to vote in the United States.\r\n",
      "The year 2008 saw the global financial crisis, which originated in the United States and had a profound impact on the world economy."
     ]
    }
   ],
   "source": [
    "!cat \"data/sentences.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47403b27",
   "metadata": {},
   "source": [
    "# Extract Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67555fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input corpus\n",
      "Preparing output file\n",
      "Extracting representations from model\n",
      "Sentence         : \"In the year 1969, Neil Armstrong became the first person to set foot on the moon during the Apollo 11 mission.\"\n",
      "Original    (021): ['In', 'the', 'year', '1969,', 'Neil', 'Armstrong', 'became', 'the', 'first', 'person', 'to', 'set', 'foot', 'on', 'the', 'moon', 'during', 'the', 'Apollo', '11', 'mission.']\n",
      "Tokenized   (025): ['[CLS]', 'in', 'the', 'year', '1969', ',', 'neil', 'armstrong', 'became', 'the', 'first', 'person', 'to', 'set', 'foot', 'on', 'the', 'moon', 'during', 'the', 'apollo', '11', 'mission', '.', '[SEP]']\n",
      "Filtered   (023): ['in', 'the', 'year', '1969', ',', 'neil', 'armstrong', 'became', 'the', 'first', 'person', 'to', 'set', 'foot', 'on', 'the', 'moon', 'during', 'the', 'apollo', '11', 'mission', '.']\n",
      "Detokenized (021): ['in', 'the', 'year', '1969,', 'neil', 'armstrong', 'became', 'the', 'first', 'person', 'to', 'set', 'foot', 'on', 'the', 'moon', 'during', 'the', 'apollo', '11', 'mission.']\n",
      "Counter: 23\n",
      "===================================================================\n",
      "Hidden states:  (13, 21, 768)\n",
      "# Extracted words:  21\n",
      "Sentence         : \"The Berlin Wall, which divided East and West Germany, stood from 1961 until its fall in 1989.\"\n",
      "Original    (017): ['The', 'Berlin', 'Wall,', 'which', 'divided', 'East', 'and', 'West', 'Germany,', 'stood', 'from', '1961', 'until', 'its', 'fall', 'in', '1989.']\n",
      "Tokenized   (022): ['[CLS]', 'the', 'berlin', 'wall', ',', 'which', 'divided', 'east', 'and', 'west', 'germany', ',', 'stood', 'from', '1961', 'until', 'its', 'fall', 'in', '1989', '.', '[SEP]']\n",
      "Filtered   (020): ['the', 'berlin', 'wall', ',', 'which', 'divided', 'east', 'and', 'west', 'germany', ',', 'stood', 'from', '1961', 'until', 'its', 'fall', 'in', '1989', '.']\n",
      "Detokenized (017): ['the', 'berlin', 'wall,', 'which', 'divided', 'east', 'and', 'west', 'germany,', 'stood', 'from', '1961', 'until', 'its', 'fall', 'in', '1989.']\n",
      "Counter: 20\n",
      "===================================================================\n",
      "Hidden states:  (13, 17, 768)\n",
      "# Extracted words:  17\n",
      "Sentence         : \"In 1776, the United States declared its independence from Great Britain with the signing of the Declaration of Independence.\"\n",
      "Original    (019): ['In', '1776,', 'the', 'United', 'States', 'declared', 'its', 'independence', 'from', 'Great', 'Britain', 'with', 'the', 'signing', 'of', 'the', 'Declaration', 'of', 'Independence.']\n",
      "Tokenized   (023): ['[CLS]', 'in', '1776', ',', 'the', 'united', 'states', 'declared', 'its', 'independence', 'from', 'great', 'britain', 'with', 'the', 'signing', 'of', 'the', 'declaration', 'of', 'independence', '.', '[SEP]']\n",
      "Filtered   (021): ['in', '1776', ',', 'the', 'united', 'states', 'declared', 'its', 'independence', 'from', 'great', 'britain', 'with', 'the', 'signing', 'of', 'the', 'declaration', 'of', 'independence', '.']\n",
      "Detokenized (019): ['in', '1776,', 'the', 'united', 'states', 'declared', 'its', 'independence', 'from', 'great', 'britain', 'with', 'the', 'signing', 'of', 'the', 'declaration', 'of', 'independence.']\n",
      "Counter: 21\n",
      "===================================================================\n",
      "Hidden states:  (13, 19, 768)\n",
      "# Extracted words:  19\n",
      "Sentence         : \"The year 1945 marked the end of World War II, with the surrender of Germany and Japan.\"\n",
      "Original    (017): ['The', 'year', '1945', 'marked', 'the', 'end', 'of', 'World', 'War', 'II,', 'with', 'the', 'surrender', 'of', 'Germany', 'and', 'Japan.']\n",
      "Tokenized   (021): ['[CLS]', 'the', 'year', '1945', 'marked', 'the', 'end', 'of', 'world', 'war', 'ii', ',', 'with', 'the', 'surrender', 'of', 'germany', 'and', 'japan', '.', '[SEP]']\n",
      "Filtered   (019): ['the', 'year', '1945', 'marked', 'the', 'end', 'of', 'world', 'war', 'ii', ',', 'with', 'the', 'surrender', 'of', 'germany', 'and', 'japan', '.']\n",
      "Detokenized (017): ['the', 'year', '1945', 'marked', 'the', 'end', 'of', 'world', 'war', 'ii,', 'with', 'the', 'surrender', 'of', 'germany', 'and', 'japan.']\n",
      "Counter: 19\n",
      "===================================================================\n",
      "Hidden states:  (13, 17, 768)\n",
      "# Extracted words:  17\n",
      "Sentence         : \"The internet as we know it today began to take shape in 1969, when the first host-to-host connection was established between two computers.\"\n",
      "Original    (023): ['The', 'internet', 'as', 'we', 'know', 'it', 'today', 'began', 'to', 'take', 'shape', 'in', '1969,', 'when', 'the', 'first', 'host-to-host', 'connection', 'was', 'established', 'between', 'two', 'computers.']\n",
      "Tokenized   (031): ['[CLS]', 'the', 'internet', 'as', 'we', 'know', 'it', 'today', 'began', 'to', 'take', 'shape', 'in', '1969', ',', 'when', 'the', 'first', 'host', '-', 'to', '-', 'host', 'connection', 'was', 'established', 'between', 'two', 'computers', '.', '[SEP]']\n",
      "Filtered   (029): ['the', 'internet', 'as', 'we', 'know', 'it', 'today', 'began', 'to', 'take', 'shape', 'in', '1969', ',', 'when', 'the', 'first', 'host', '-', 'to', '-', 'host', 'connection', 'was', 'established', 'between', 'two', 'computers', '.']\n",
      "Detokenized (023): ['the', 'internet', 'as', 'we', 'know', 'it', 'today', 'began', 'to', 'take', 'shape', 'in', '1969,', 'when', 'the', 'first', 'host-to-host', 'connection', 'was', 'established', 'between', 'two', 'computers.']\n",
      "Counter: 29\n",
      "===================================================================\n",
      "Hidden states:  (13, 23, 768)\n",
      "# Extracted words:  23\n",
      "Sentence         : \"The devastating earthquake and tsunami in Japan occurred in 2011, causing widespread destruction and a nuclear disaster at the Fukushima Daiichi power plant.\"\n",
      "Original    (023): ['The', 'devastating', 'earthquake', 'and', 'tsunami', 'in', 'Japan', 'occurred', 'in', '2011,', 'causing', 'widespread', 'destruction', 'and', 'a', 'nuclear', 'disaster', 'at', 'the', 'Fukushima', 'Daiichi', 'power', 'plant.']\n",
      "Tokenized   (029): ['[CLS]', 'the', 'devastating', 'earthquake', 'and', 'tsunami', 'in', 'japan', 'occurred', 'in', '2011', ',', 'causing', 'widespread', 'destruction', 'and', 'a', 'nuclear', 'disaster', 'at', 'the', 'fu', '##kushima', 'dai', '##ichi', 'power', 'plant', '.', '[SEP]']\n",
      "Filtered   (027): ['the', 'devastating', 'earthquake', 'and', 'tsunami', 'in', 'japan', 'occurred', 'in', '2011', ',', 'causing', 'widespread', 'destruction', 'and', 'a', 'nuclear', 'disaster', 'at', 'the', 'fu', '##kushima', 'dai', '##ichi', 'power', 'plant', '.']\n",
      "Detokenized (023): ['the', 'devastating', 'earthquake', 'and', 'tsunami', 'in', 'japan', 'occurred', 'in', '2011,', 'causing', 'widespread', 'destruction', 'and', 'a', 'nuclear', 'disaster', 'at', 'the', 'fu##kushima', 'dai##ichi', 'power', 'plant.']\n",
      "Counter: 27\n",
      "===================================================================\n",
      "Hidden states:  (13, 23, 768)\n",
      "# Extracted words:  23\n",
      "Sentence         : \"The Chernobyl nuclear disaster took place in 1986, when a reactor at the Chernobyl power plant in Ukraine exploded, releasing a significant amount of radioactive material.\"\n",
      "Original    (026): ['The', 'Chernobyl', 'nuclear', 'disaster', 'took', 'place', 'in', '1986,', 'when', 'a', 'reactor', 'at', 'the', 'Chernobyl', 'power', 'plant', 'in', 'Ukraine', 'exploded,', 'releasing', 'a', 'significant', 'amount', 'of', 'radioactive', 'material.']\n",
      "Tokenized   (035): ['[CLS]', 'the', 'cher', '##nob', '##yl', 'nuclear', 'disaster', 'took', 'place', 'in', '1986', ',', 'when', 'a', 'reactor', 'at', 'the', 'cher', '##nob', '##yl', 'power', 'plant', 'in', 'ukraine', 'exploded', ',', 'releasing', 'a', 'significant', 'amount', 'of', 'radioactive', 'material', '.', '[SEP]']\n",
      "Filtered   (033): ['the', 'cher', '##nob', '##yl', 'nuclear', 'disaster', 'took', 'place', 'in', '1986', ',', 'when', 'a', 'reactor', 'at', 'the', 'cher', '##nob', '##yl', 'power', 'plant', 'in', 'ukraine', 'exploded', ',', 'releasing', 'a', 'significant', 'amount', 'of', 'radioactive', 'material', '.']\n",
      "Detokenized (026): ['the', 'cher##nob##yl', 'nuclear', 'disaster', 'took', 'place', 'in', '1986,', 'when', 'a', 'reactor', 'at', 'the', 'cher##nob##yl', 'power', 'plant', 'in', 'ukraine', 'exploded,', 'releasing', 'a', 'significant', 'amount', 'of', 'radioactive', 'material.']\n",
      "Counter: 33\n",
      "===================================================================\n",
      "Hidden states:  (13, 26, 768)\n",
      "# Extracted words:  26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence         : \"The year 1492 is famous for Christopher Columbus's first voyage to the Americas, which opened up a new era of exploration and colonization.\"\n",
      "Original    (023): ['The', 'year', '1492', 'is', 'famous', 'for', 'Christopher', \"Columbus's\", 'first', 'voyage', 'to', 'the', 'Americas,', 'which', 'opened', 'up', 'a', 'new', 'era', 'of', 'exploration', 'and', 'colonization.']\n",
      "Tokenized   (030): ['[CLS]', 'the', 'year', '149', '##2', 'is', 'famous', 'for', 'christopher', 'columbus', \"'\", 's', 'first', 'voyage', 'to', 'the', 'americas', ',', 'which', 'opened', 'up', 'a', 'new', 'era', 'of', 'exploration', 'and', 'colonization', '.', '[SEP]']\n",
      "Filtered   (028): ['the', 'year', '149', '##2', 'is', 'famous', 'for', 'christopher', 'columbus', \"'\", 's', 'first', 'voyage', 'to', 'the', 'americas', ',', 'which', 'opened', 'up', 'a', 'new', 'era', 'of', 'exploration', 'and', 'colonization', '.']\n",
      "Detokenized (023): ['the', 'year', '149##2', 'is', 'famous', 'for', 'christopher', \"columbus's\", 'first', 'voyage', 'to', 'the', 'americas,', 'which', 'opened', 'up', 'a', 'new', 'era', 'of', 'exploration', 'and', 'colonization.']\n",
      "Counter: 28\n",
      "===================================================================\n",
      "Hidden states:  (13, 23, 768)\n",
      "# Extracted words:  23\n",
      "Sentence         : \"The Women's Suffrage Movement achieved a significant victory in 1920 with the ratification of the 19th Amendment, granting women the right to vote in the United States.\"\n",
      "Original    (027): ['The', \"Women's\", 'Suffrage', 'Movement', 'achieved', 'a', 'significant', 'victory', 'in', '1920', 'with', 'the', 'ratification', 'of', 'the', '19th', 'Amendment,', 'granting', 'women', 'the', 'right', 'to', 'vote', 'in', 'the', 'United', 'States.']\n",
      "Tokenized   (033): ['[CLS]', 'the', 'women', \"'\", 's', 'suffrage', 'movement', 'achieved', 'a', 'significant', 'victory', 'in', '1920', 'with', 'the', 'ratification', 'of', 'the', '19th', 'amendment', ',', 'granting', 'women', 'the', 'right', 'to', 'vote', 'in', 'the', 'united', 'states', '.', '[SEP]']\n",
      "Filtered   (031): ['the', 'women', \"'\", 's', 'suffrage', 'movement', 'achieved', 'a', 'significant', 'victory', 'in', '1920', 'with', 'the', 'ratification', 'of', 'the', '19th', 'amendment', ',', 'granting', 'women', 'the', 'right', 'to', 'vote', 'in', 'the', 'united', 'states', '.']\n",
      "Detokenized (027): ['the', \"women's\", 'suffrage', 'movement', 'achieved', 'a', 'significant', 'victory', 'in', '1920', 'with', 'the', 'ratification', 'of', 'the', '19th', 'amendment,', 'granting', 'women', 'the', 'right', 'to', 'vote', 'in', 'the', 'united', 'states.']\n",
      "Counter: 31\n",
      "===================================================================\n",
      "Hidden states:  (13, 27, 768)\n",
      "# Extracted words:  27\n",
      "Sentence         : \"The year 2008 saw the global financial crisis, which originated in the United States and had a profound impact on the world economy.\"\n",
      "Original    (023): ['The', 'year', '2008', 'saw', 'the', 'global', 'financial', 'crisis,', 'which', 'originated', 'in', 'the', 'United', 'States', 'and', 'had', 'a', 'profound', 'impact', 'on', 'the', 'world', 'economy.']\n",
      "Tokenized   (027): ['[CLS]', 'the', 'year', '2008', 'saw', 'the', 'global', 'financial', 'crisis', ',', 'which', 'originated', 'in', 'the', 'united', 'states', 'and', 'had', 'a', 'profound', 'impact', 'on', 'the', 'world', 'economy', '.', '[SEP]']\n",
      "Filtered   (025): ['the', 'year', '2008', 'saw', 'the', 'global', 'financial', 'crisis', ',', 'which', 'originated', 'in', 'the', 'united', 'states', 'and', 'had', 'a', 'profound', 'impact', 'on', 'the', 'world', 'economy', '.']\n",
      "Detokenized (023): ['the', 'year', '2008', 'saw', 'the', 'global', 'financial', 'crisis,', 'which', 'originated', 'in', 'the', 'united', 'states', 'and', 'had', 'a', 'profound', 'impact', 'on', 'the', 'world', 'economy.']\n",
      "Counter: 25\n",
      "===================================================================\n",
      "Hidden states:  (13, 23, 768)\n",
      "# Extracted words:  23\n"
     ]
    }
   ],
   "source": [
    "transformers_extractor.extract_representations('bert-base-uncased',\n",
    "    \"data/sentences.txt\",\n",
    "    'activations.json',\n",
    "    aggregation=\"average\" #last, first\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a591b599",
   "metadata": {},
   "source": [
    "# Annotate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6391950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json activations from activations.json...\n",
      "10 13.0\n",
      "Creating binary dataset ...\n",
      "Number of Positive examples:  9\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(19\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m|20\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mannotate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/sentences.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mactivations.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mannotations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/alt/mt/tcav-basel/NeuroX/neurox/data/annotate.py:143\u001b[0m, in \u001b[0;36mannotate_data\u001b[0;34m(source_path, activations_path, binary_filter, output_prefix, output_type, decompose_layers, filter_layers)\u001b[0m\n\u001b[1;32m    138\u001b[0m tokens \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mload_data(\n\u001b[1;32m    139\u001b[0m     source_path, source_path, activations, max_sent_l\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    142\u001b[0m words, labels, activations \u001b[38;5;241m=\u001b[39m _create_binary_data(tokens, activations, binary_filter)\n\u001b[0;32m--> 143\u001b[0m activations \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    144\u001b[0m     np\u001b[38;5;241m.\u001b[39mswapaxes(a\u001b[38;5;241m.\u001b[39mreshape((a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], num_layers, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m activations\n\u001b[1;32m    145\u001b[0m ]\n\u001b[1;32m    146\u001b[0m data_utils\u001b[38;5;241m.\u001b[39msave_files(\n\u001b[1;32m    147\u001b[0m     words,\n\u001b[1;32m    148\u001b[0m     labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     filter_layers,\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32m/alt/mt/tcav-basel/NeuroX/neurox/data/annotate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    138\u001b[0m tokens \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mload_data(\n\u001b[1;32m    139\u001b[0m     source_path, source_path, activations, max_sent_l\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    142\u001b[0m words, labels, activations \u001b[38;5;241m=\u001b[39m _create_binary_data(tokens, activations, binary_filter)\n\u001b[1;32m    143\u001b[0m activations \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 144\u001b[0m     np\u001b[38;5;241m.\u001b[39mswapaxes(a\u001b[38;5;241m.\u001b[39mreshape((\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, num_layers, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m activations\n\u001b[1;32m    145\u001b[0m ]\n\u001b[1;32m    146\u001b[0m data_utils\u001b[38;5;241m.\u001b[39msave_files(\n\u001b[1;32m    147\u001b[0m     words,\n\u001b[1;32m    148\u001b[0m     labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     filter_layers,\n\u001b[1;32m    154\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r\"\\b(19\\d{2}|20\\d{2})\\b\")\n",
    "annotate_data(\"data/sentences.txt\", \"activations.json\", pattern, \"annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e37fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
